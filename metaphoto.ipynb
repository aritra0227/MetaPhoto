{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x,y):\n",
    "    return np.sum((x-y)**2, axis=-1)\n",
    "\n",
    "# image: (SIZE, SIZE, C)\n",
    "# candidates: (N, TILE_SIZE, TILE_SIZE, C)\n",
    "def create_metaphoto(image, candidates, loss_fn=mse, k=10, with_replacement=True):\n",
    "    NUM_CANDIDATES, TILE_SIZE, _, _ = candidates.shape\n",
    "    IMAGE_SIZE, _, CHANNELS = image.shape\n",
    "    TILES_PER_DIM = IMAGE_SIZE // TILE_SIZE\n",
    "    TOTAL_TILES = TILES_PER_DIM * TILES_PER_DIM\n",
    "\n",
    "\n",
    "    # breaks image into TILES_PER_DIM x TILES_PER_DIM grid of subimages\n",
    "    grid = image.reshape(TILES_PER_DIM, TILE_SIZE, TILES_PER_DIM, TILE_SIZE, CHANNELS).swapaxes(1, 2)\n",
    "\n",
    "    # flattens grid into sequence of subimages\n",
    "    grid = grid.reshape(-1, *grid.shape[2:])\n",
    "\n",
    "    # for broadcasting to work with the following line\n",
    "    grid = np.expand_dims(grid, axis=1)\n",
    "\n",
    "    # loss = (grid - candidates)**2\n",
    "    loss = loss_fn(grid, candidates)\n",
    "\n",
    "    # flatten the differences into single dimension per image\n",
    "    loss = loss.reshape(*loss.shape[:2], -1)\n",
    "\n",
    "    total_loss = np.sum(loss, axis=-1)\n",
    "\n",
    "    if(with_replacement):\n",
    "        best = np.argmin(total_loss, axis=-1)\n",
    "        best_k = np.argpartition(total_loss, k, axis=-1)[:,:k]\n",
    "        chosen_imgs = np.random.randint(0, k, size=best_k.shape[0])\n",
    "        best = best_k[np.arange(best_k.shape[0]),chosen_imgs]\n",
    "\n",
    "    else:\n",
    "        # iterate over tiles in random order, pick best image that hasnt been used yet\n",
    "        # otherwise images near the bottom will be bad\n",
    "        assert TOTAL_TILES <= NUM_CANDIDATES\n",
    "        sorted_candidates = np.argsort(total_loss, axis=-1)\n",
    "        is_img_unused = np.ones(NUM_CANDIDATES, dtype=np.int32)\n",
    "        best = np.ones(sorted_candidates.shape[0], dtype=np.int32)\n",
    "        for i in np.random.permutation(sorted_candidates.shape[0]):\n",
    "            row = sorted_candidates[i]\n",
    "            min_unused_idx = row[np.argmax(is_img_unused[row])]\n",
    "            is_img_unused[min_unused_idx] = 0\n",
    "            best[i] = min_unused_idx\n",
    "\n",
    "    # get best tiles and reshape back TILES_PER_DIM x TILES_PER_DIM grid of subimages\n",
    "    tiles = candidates[best]\n",
    "    tiles = tiles.reshape(TILES_PER_DIM, TILES_PER_DIM, *tiles.shape[1:])\n",
    "\n",
    "    # consolidate grid of subimages into full image\n",
    "    metaphoto = tiles.swapaxes(1, 2).reshape(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "    return metaphoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 1024\n",
    "TILE_SIZE = 16\n",
    "CANDIDATES = 2000\n",
    "\n",
    "transform_main = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_candidates = transforms.Compose([\n",
    "    transforms.Resize(TILE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "I_HAVE_THE_DATASET = True\n",
    "dataset_main = datasets.Places365(root='./data', split='val', transform=transform_main, small=True, download=not I_HAVE_THE_DATASET)\n",
    "dataset_candidates = datasets.Places365(root='./data', split='val', transform=transform_candidates, small=True, download=not I_HAVE_THE_DATASET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3145728 into shape (42,24,42,24,3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mw/t36tn2_10qj8426cwsc1z8440000gn/T/ipykernel_97589/2900389640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmetaphoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_metaphoto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_replacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/mw/t36tn2_10qj8426cwsc1z8440000gn/T/ipykernel_97589/1604090695.py\u001b[0m in \u001b[0;36mcreate_metaphoto\u001b[0;34m(image, candidates, loss_fn, k, with_replacement)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# breaks image into TILES_PER_DIM x TILES_PER_DIM grid of subimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTILES_PER_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTILE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTILES_PER_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTILE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# flattens grid into sequence of subimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3145728 into shape (42,24,42,24,3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "target_img_path = 'koalas.jpg'\n",
    "example = transform_main(PIL.Image.open(os.path.join(target_img_path)))\n",
    "example = example.permute(1, 2, 0).numpy()\n",
    "example = example[:,:,:3]\n",
    "\n",
    "candidates: torch.Tensor = next(iter(torch.utils.data.DataLoader(dataset_candidates, batch_size=CANDIDATES, shuffle=True)))[0]\n",
    "candidates = candidates.permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "metaphoto = create_metaphoto(example, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = transforms.ToPILImage()(torch.from_numpy(example).permute(2, 0, 1))\n",
    "post =transforms.ToPILImage()(torch.from_numpy(metaphoto).permute(2, 0, 1))\n",
    "pre.show()\n",
    "post.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env_pytorch': conda)",
   "language": "python",
   "name": "python361364bitenvpytorchcondadd6128d829864dc48da9d2ff6375bbc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15-final"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faa379d4b1a9800b08925fff17ac1148989401b3ce4c9ea153fdccf698923f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}